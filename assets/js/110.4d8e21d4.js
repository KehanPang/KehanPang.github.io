(window.webpackJsonp=window.webpackJsonp||[]).push([[110],{477:function(a,t,s){"use strict";s.r(t);var e=s(3),r=Object(e.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"llm-fine-tune-学习记录"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#llm-fine-tune-学习记录"}},[a._v("#")]),a._v(" LLM Fine-tune 学习记录")]),a._v(" "),t("ClientOnly",[t("title-pv")],1),a._v(" "),t("h2",{attrs:{id:"环境备忘录"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#环境备忘录"}},[a._v("#")]),a._v(" 环境备忘录")]),a._v(" "),t("p",[a._v("北航服务器：LLM虚拟环境 source LLM/bin/activate\n51.10：conda环境 hence（但是该服务器并未部署llm模型）\n51.11：conda环境 llama_factory")]),a._v(" "),t("h2",{attrs:{id:"参数字典"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#参数字典"}},[a._v("#")]),a._v(" 参数字典")]),a._v(" "),t("ul",[t("li",[a._v("stage\n"),t("ul",[t("li",[a._v("SFT：指令监督微调")]),a._v(" "),t("li",[a._v("pt：预训练")]),a._v(" "),t("li",[a._v("rm：奖励模型")])])]),a._v(" "),t("li",[a._v("max_samples：样本数量")]),a._v(" "),t("li",[a._v("fp16/bf16：精度高，范围有限/范围宽，精度有限")]),a._v(" "),t("li",[a._v("gradient_accumulation_steps：实际模型更新权重之前，前向传播和反向传播的次数")]),a._v(" "),t("li",[a._v("max_gradient_norm：梯度的某个范数如果超过了某个阈值，则进行梯度裁剪")]),a._v(" "),t("li",[a._v("evaluation_strategy\n"),t("ul",[t("li",[a._v("no：训练时不做评估")]),a._v(" "),t("li",[a._v("steps：在每个eval_steps都进行评估")]),a._v(" "),t("li",[a._v("epoch：在每个epoch结束时评估")])])]),a._v(" "),t("li",[a._v("per_device_train_batch_size：批处理大小：每块 GPU 上处理的样本数量")]),a._v(" "),t("li",[a._v("lr_scheduler_type cosine：学习率调节器：采用的学习率调节器名称")]),a._v(" "),t("li",[a._v("save_steps：保存间隔：每两次断点保存间的更新步数")]),a._v(" "),t("li",[a._v("plot_loss：绘制损失函数图")]),a._v(" "),t("li",[a._v("lora_target：lora作用模块，不同大模型有不同的作用模块")]),a._v(" "),t("li",[a._v("overwrite_cache：是否覆盖cache，在重复训练一个数据集时可以删掉")]),a._v(" "),t("li",[a._v("predict_with_generate：指示在生成模型的预测时使用生成模式")]),a._v(" "),t("li",[a._v("val_size和test_size分别表示用于验证集和测试集的数据比例")]),a._v(" "),t("li",[a._v("export_legacy_format：为True时输出bin，为false时输出safetensor格式")])]),a._v(" "),t("h2",{attrs:{id:"数据格式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#数据格式"}},[a._v("#")]),a._v(" 数据格式")]),a._v(" "),t("h2",{attrs:{id:"训练"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#训练"}},[a._v("#")]),a._v(" 训练")]),a._v(" "),t("p",[a._v("训练时需要的命令：")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token shebang important"}},[a._v("#!/bin/bash")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("CUDA_VISIBLE_DEVICES")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0,1")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("WANDB_MODE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v("'offline'")]),a._v("\n\naccelerate launch "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--config_file")]),a._v(" config.yaml "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/src/train_bash.py "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--stage")]),a._v(" sft "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--do_train")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--model_name_or_path")]),a._v(" /home/LAB/pangkh/LLM_factory/Llama-2-7b-hf "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--dataset")]),a._v(" alpaca_gpt4_en,glaive_toolcall "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--dataset_dir")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/data "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--template")]),a._v(" default "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--finetuning_type")]),a._v(" lora "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--lora_target")]),a._v(" q_proj,v_proj "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--output_dir")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/saves/LLaMA2-7B/lora/sft "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--overwrite_cache")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--overwrite_output_dir")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--cutoff_len")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1024")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--per_device_train_batch_size")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--per_device_eval_batch_size")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--gradient_accumulation_steps")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--lr_scheduler_type")]),a._v(" cosine "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--logging_steps")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--save_steps")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("100")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--eval_steps")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("100")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--evaluation_strategy")]),a._v(" steps "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--load_best_model_at_end")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--learning_rate")]),a._v(" 5e-5 "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--num_train_epochs")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3.0")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--max_samples")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3000")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--val_size")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--plot_loss")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--fp16")]),a._v("\n\n")])])]),t("h2",{attrs:{id:"评估"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#评估"}},[a._v("#")]),a._v(" 评估")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("CUDA_VISIBLE_DEVICES")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" python src/evaluate.py "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--model_name_or_path")]),a._v(" path_to_llama_model "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--finetuning_type")]),a._v(" lora "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--checkpoint_dir")]),a._v(" path_to_checkpoint "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--template")]),a._v(" vanilla "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--task")]),a._v(" ceval "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--split")]),a._v(" validation "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--lang")]),a._v(" zh "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--n_shot")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--batch_size")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v("\n")])])]),t("h2",{attrs:{id:"预测"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#预测"}},[a._v("#")]),a._v(" 预测")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("CUDA_VISIBLE_DEVICES")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" python src/train_bash.py "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--stage")]),a._v(" sft "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--model_name_or_path")]),a._v(" path_to_llama_model "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--do_predict")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--dataset")]),a._v(" alpaca_gpt4_zh "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--template")]),a._v(" default "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--finetuning_type")]),a._v(" lora "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--checkpoint_dir")]),a._v(" path_to_checkpoint "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--output_dir")]),a._v(" path_to_predict_result "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--per_device_eval_batch_size")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--max_samples")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("100")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("                     "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 最大样本数：每个数据集最多使用的样本数")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--predict_with_generate")]),a._v("\n")])])]),t("h2",{attrs:{id:"合并"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#合并"}},[a._v("#")]),a._v(" 合并")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("python src/export_model.py "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--model_name_or_path")]),a._v(" path_to_llama_model "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--adapter_name_or_path")]),a._v(" path_to_checkpoint "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--template")]),a._v(" default "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--finetuning_type")]),a._v(" lora "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--export_dir")]),a._v(" path_to_export "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--export_size")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("--export_legacy_format")]),a._v(" False\n")])])]),t("h2",{attrs:{id:"使用vllm合并"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用vllm合并"}},[a._v("#")]),a._v(" 使用vLLM合并")]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("\n\n")])])]),t("h2",{attrs:{id:"参考链接"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#参考链接"}},[a._v("#")]),a._v(" 参考链接")]),a._v(" "),t("p",[t("a",{attrs:{href:"https://github.com/hiyouga/LLaMA-Factory",target:"_blank",rel:"noopener noreferrer"}},[a._v("LLaMA-Factory"),t("OutboundLink")],1)]),a._v(" "),t("ClientOnly",[t("leave")],1)],1)}),[],!1,null,null,null);t.default=r.exports}}]);