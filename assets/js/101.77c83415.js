(window.webpackJsonp=window.webpackJsonp||[]).push([[101],{469:function(t,a,s){"use strict";s.r(a);var r=s(3),e=Object(r.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"大模型压缩"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#大模型压缩"}},[t._v("#")]),t._v(" 大模型压缩")]),t._v(" "),a("ClientOnly",[a("title-pv")],1),t._v(" "),a("h2",{attrs:{id:"基础概念"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基础概念"}},[t._v("#")]),t._v(" 基础概念")]),t._v(" "),a("p",[t._v("模型压缩算法旨在将一个庞大而复杂的大模型转化为一个精简的小模型。")]),t._v(" "),a("h3",{attrs:{id:"中-大型语言模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#中-大型语言模型"}},[t._v("#")]),t._v(" 中/大型语言模型")]),t._v(" "),a("p",[t._v("中等规模的语言模型参数规模在1亿以下，大规模的语言模型参数规模在1亿以上。大规模的语言模型相较于中等规模的语言模型，具有更强的泛化能力和通用性，能够处理更复杂的任务。然而，大规模的语言模型在压缩和加速方面也面临着更大的挑战。")]),t._v(" "),a("h3",{attrs:{id:""}},[a("a",{staticClass:"header-anchor",attrs:{href:"#"}},[t._v("#")])]),t._v(" "),a("h2",{attrs:{id:"量化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#量化"}},[t._v("#")]),t._v(" 量化")]),t._v(" "),a("p",[t._v("量化是指将输入值从一个较大的连续集合映射到一个较小的有限集合的过程。它是降低大型语言模型内存成本和加速推理的最直接方法，特别是在支持低比特数据类型快速操作的硬件上。量化方法有许多优点，例如减少内存占用、提高推理速度等。")]),t._v(" "),a("h2",{attrs:{id:"剪枝"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#剪枝"}},[t._v("#")]),t._v(" 剪枝")]),t._v(" "),a("h2",{attrs:{id:"知识蒸馏"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#知识蒸馏"}},[t._v("#")]),t._v(" 知识蒸馏")]),t._v(" "),a("h2",{attrs:{id:"紧凑架构设计"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#紧凑架构设计"}},[t._v("#")]),t._v(" 紧凑架构设计")]),t._v(" "),a("h2",{attrs:{id:"硬件加速"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#硬件加速"}},[t._v("#")]),t._v(" 硬件加速")]),t._v(" "),a("h2",{attrs:{id:"低秩分解"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#低秩分解"}},[t._v("#")]),t._v(" 低秩分解")]),t._v(" "),a("ClientOnly",[a("leave")],1)],1)}),[],!1,null,null,null);a.default=e.exports}}]);