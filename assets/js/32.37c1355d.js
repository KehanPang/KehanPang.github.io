(window.webpackJsonp=window.webpackJsonp||[]).push([[32],{400:function(_,v,l){"use strict";l.r(v);var a=l(3),t=Object(a.a)({},(function(){var _=this,v=_._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[v("h1",{attrs:{id:"实习面试记录"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#实习面试记录"}},[_._v("#")]),_._v(" 实习面试记录")]),_._v(" "),v("ClientOnly",[v("title-pv")],1),_._v(" "),v("h2",{attrs:{id:"百川智能llm应用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#百川智能llm应用"}},[_._v("#")]),_._v(" 百川智能LLM应用")]),_._v(" "),v("h3",{attrs:{id:"_9-14-一面-×"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_9-14-一面-×"}},[_._v("#")]),_._v(" 9.14 一面（×）")]),_._v(" "),v("ul",[v("li",[_._v("自我介绍：为什么对LLM感兴趣，对LLM有多少了解？")]),_._v(" "),v("li",[_._v("项目经历：论文核心创新点，为什么LLM在这个场景下相较于Bert有优势")]),_._v(" "),v("li",[_._v("Encoder-decoder、Encode-only和Decoder-only架构的区别与优势")]),_._v(" "),v("li",[_._v("RAG的技术手段")]),_._v(" "),v("li",[_._v("如何对RAG检索到的文档选优？")]),_._v(" "),v("li",[_._v("模型无法有效利用RAG检索到的文件该怎么办？")]),_._v(" "),v("li",[_._v("代码手撕：多头注意力")]),_._v(" "),v("li",[_._v("GCN、GAT的基本思想？")]),_._v(" "),v("li",[_._v("GAT和自注意力机制的联系？")])]),_._v(" "),v("h2",{attrs:{id:"美团基座llm"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#美团基座llm"}},[_._v("#")]),_._v(" 美团基座LLM")]),_._v(" "),v("h3",{attrs:{id:"_9-19-一面-√"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_9-19-一面-√"}},[_._v("#")]),_._v(" 9.19 一面（√）")]),_._v(" "),v("ul",[v("li",[_._v("自我介绍")]),_._v(" "),v("li",[_._v("项目经历\n"),v("ul",[v("li",[_._v("论文核心创新点")]),_._v(" "),v("li",[_._v("用了多少数据进行训练？")]),_._v(" "),v("li",[_._v("这些数据是怎么获取的？")]),_._v(" "),v("li",[_._v("用的什么模型？多大的模型？为什么用这个模型？")]),_._v(" "),v("li",[_._v("为什么不选用QWen、BaiChuan、GLM-4等大模型？")]),_._v(" "),v("li",[_._v("抽取出的特征是手动预设的还是自动抽取的？")]),_._v(" "),v("li",[_._v("在同一场景下需不需要进行特征对齐，也就是规定哪个位置必须是什么属性？比如第一个位置必须是名字，第二个位置必须是年龄？")]),_._v(" "),v("li",[_._v("你的项目有没有微调大模型？为什么要微调？")]),_._v(" "),v("li",[_._v("SFT前后，特征能正确对齐吗？")]),_._v(" "),v("li",[_._v("对于亚马逊的爬虫网页信息来说，有哪些内容是可以用来哺育大模型的？")]),_._v(" "),v("li",[_._v("如果有1T级别的数据，怎么选取出1M级别适合大模型训练的数据？")])])]),_._v(" "),v("li",[_._v("目前有接触到哪些RAG的科研？")]),_._v(" "),v("li",[_._v("这些科研落地了吗？")]),_._v(" "),v("li",[_._v("了解o1吗？o1-mini和o1相较于GPT-4做了哪些改进？")]),_._v(" "),v("li",[_._v("你对o1的逻辑计算能力是怎么看待的？")]),_._v(" "),v("li",[_._v("多智能体协调会遇到什么问题？")]),_._v(" "),v("li",[_._v("智能体是怎么样调用工具的？")]),_._v(" "),v("li",[_._v("LlaMA-2和LlaMA-3的差异？（训练数据差异，模型结构差异，适合任务差异）")]),_._v(" "),v("li",[_._v("Mistral-7B和LlaMA-3-8B的差异？（训练数据差异，模型结构差异，适合任务差异）")]),_._v(" "),v("li",[_._v("有没有看过开源大模型的技术报告？")]),_._v(" "),v("li",[_._v("代码手撕：K-means")]),_._v(" "),v("li",[_._v("反问环节：\n"),v("ul",[v("li",[_._v("目前贵司在做的是什么大模型？准备用在什么业务上？")]),_._v(" "),v("li",[_._v("您对工业界大模型方向是怎么看的？\n")]),_._v(" "),v("li",[_._v("您觉得我有哪些地方需要加强学习？\n"),v("ul",[v("li",[_._v("加强对前沿知识、模型的深入理解、多一些实操经验，尤其是研究方向有差异的人如果想从事大模型行业，就需要付出更多的努力。")])])])])])]),_._v(" "),v("h3",{attrs:{id:"_9-23-二面"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_9-23-二面"}},[_._v("#")]),_._v(" 9.23 二面")]),_._v(" "),v("h2",{attrs:{id:"百度大模型"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#百度大模型"}},[_._v("#")]),_._v(" 百度大模型")]),_._v(" "),v("h3",{attrs:{id:"_9-20-一面"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_9-20-一面"}},[_._v("#")]),_._v(" 9.20 一面")]),_._v(" "),v("h2",{attrs:{id:"华为大模型"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#华为大模型"}},[_._v("#")]),_._v(" 华为大模型")]),_._v(" "),v("ClientOnly",[v("leave")],1)],1)}),[],!1,null,null,null);v.default=t.exports}}]);